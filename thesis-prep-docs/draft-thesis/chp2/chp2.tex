%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Chapter 2: Literature Review
%% Indian Institute of Information Technology Kalyani
%% Deep Learning-Based Polyp Detection in Colonoscopy Videos Using YOLOv8
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter[Literature Review]{Literature Review}
\label{chp2}

\section{Introduction}
\label{chp2.1}

This chapter provides a comprehensive review of the literature on automated polyp detection systems, covering traditional machine learning approaches, deep learning methodologies, and specifically YOLO-based object detection in medical imaging. The review is organized chronologically and thematically to trace the evolution of techniques and identify gaps that this research addresses.

\section{Traditional Polyp Detection Methods}
\label{chp2.2}

\subsection{Hand-Crafted Feature-Based Approaches}

Early automated polyp detection systems relied on manually engineered features and classical machine learning classifiers.

\textbf{Texture and Color Features (2000-2010):}

Karkanis et al. \cite{karkanis2003computer} pioneered computer-aided polyp detection using color wavelet covariance features combined with neural networks, achieving 97\% sensitivity on a limited dataset. However, the approach struggled with generalization due to:
\begin{itemize}
\item Dependence on controlled lighting conditions
\item High false positive rates in complex backgrounds
\item Inability to handle diverse polyp morphologies
\end{itemize}

Hwang et al. \cite{hwang2007polyp} developed a polyp detection system using shape and color features with support vector machines (SVM), reporting 90\% sensitivity with 10\% false positives. The method extracted:
\begin{itemize}
\item Color histogram features in RGB and HSV spaces
\item Edge detection responses
\item Shape descriptors (circularity, compactness)
\end{itemize}

\textbf{Limitations of Traditional Methods:}
\begin{enumerate}
\item Require extensive domain expertise for feature engineering
\item Poor generalization to unseen polyp appearances
\item High computational cost for real-time processing
\item Difficulty handling variable lighting and tissue textures
\item Manual parameter tuning for different datasets
\end{enumerate}

\subsection{Region-Based Detection}

Bernal et al. \cite{bernal2012towards} proposed a valley-based region detection approach exploiting the depression characteristic of polyp boundaries. The method identified potential polyp regions through:
\begin{itemize}
\item Valley detection in grayscale intensity profiles
\item Geometric filtering based on polyp shape priors
\item Energy minimization for boundary refinement
\end{itemize}

While achieving 70\% detection rate, the approach suffered from:
\begin{itemize}
\item High false positives from fold structures mimicking valleys
\item Failure on flat polyps lacking depression characteristics
\item Sensitivity to image quality and artifacts
\end{itemize}

\section{Deep Learning Revolution in Medical Imaging}
\label{chp2.3}

\subsection{Convolutional Neural Networks for Polyp Detection}

The introduction of AlexNet \cite{krizhevsky2012imagenet} in 2012 marked the beginning of the deep learning era in computer vision, quickly extending to medical applications.

\textbf{Early CNN Approaches (2015-2017):}

Park and Sargent \cite{park2016automatic} applied CNNs for colonoscopy frame classification, achieving 84\% accuracy in distinguishing polyp frames from normal tissue. The study demonstrated:
\begin{itemize}
\item Automatic feature learning superior to hand-crafted features
\item Transfer learning from ImageNet improving performance
\item Potential for real-time screening assistance
\end{itemize}

Tajbakhsh et al. \cite{tajbakhsh2016convolutional} conducted a comprehensive study comparing various CNN architectures for polyp detection, including AlexNet, VGGNet, and GoogLeNet. Key findings included:
\begin{itemize}
\item Deeper networks (VGG-16) outperformed shallow architectures
\item Data augmentation critical for small medical datasets
\item Fine-tuning pretrained models superior to training from scratch
\item Achieved AUC of 0.97 on classification task
\end{itemize}

\subsection{Semantic Segmentation for Polyp Localization}

Pixel-level segmentation provides precise polyp boundaries compared to classification or detection.

\textbf{Fully Convolutional Networks (FCN):}

Long et al. \cite{long2015fully} introduced FCN for semantic segmentation, adapted for polyp segmentation by Akbari et al. \cite{akbari2018polyp}. The approach:
\begin{itemize}
\item Replaced fully connected layers with convolutional layers
\item Enabled dense prediction for pixel-wise classification
\item Used skip connections to preserve spatial information
\item Achieved 83\% Dice coefficient on polyp boundaries
\end{itemize}

\textbf{U-Net Architecture:}

Ronneberger et al. \cite{ronneberger2015unet} proposed U-Net for biomedical image segmentation, becoming the dominant architecture for polyp segmentation.

Key characteristics:
\begin{itemize}
\item Symmetric encoder-decoder structure
\item Skip connections preserving fine-grained details
\item Effective with limited training data
\item Fast inference suitable for clinical use
\end{itemize}

Polyp segmentation applications:
\begin{itemize}
\item Brandao et al. \cite{brandao2017fully}: 88\% F1-score on CVC-ClinicDB
\item Fang et al. \cite{fang2019selective}: Selective feature aggregation improving boundary accuracy
\item Zhou et al. \cite{zhou2018unetpp}: U-Net++ with nested skip pathways achieving 90\% Dice coefficient
\end{itemize}

\textbf{Advanced Segmentation Architectures:}

Recent works have pushed segmentation performance higher:
\begin{itemize}
\item \textbf{PraNet} \cite{fan2020pranet}: Parallel reverse attention network achieving 93.8\% Dice on Kvasir-SEG
\item \textbf{HarDNet-MSEG} \cite{huang2021hardnet}: Hardware-efficient architecture with 91.2\% mean Dice
\item \textbf{SANet} \cite{wei2021shallow}: Shallow attention network balancing accuracy and speed
\end{itemize}

\subsection{Limitations of Segmentation for Real-Time Detection}

While segmentation provides accurate polyp boundaries, several limitations exist for clinical deployment:
\begin{enumerate}
\item Computationally expensive for high-resolution videos
\item Provides more information than needed for detection
\item Complex post-processing to convert masks to bounding boxes
\item Difficult to interpret confidence for clinical decision-making
\item Training requires pixel-level annotations (labor-intensive)
\end{enumerate}

\section{Object Detection Approaches for Polyp Detection}
\label{chp2.4}

Object detection provides a middle ground between classification and segmentation, offering both localization and classification with bounding boxes.

\subsection{Two-Stage Detectors}

\textbf{Faster R-CNN Applications:}

Shin et al. \cite{shin2018automatic} applied Faster R-CNN for polyp detection in wireless capsule endoscopy, achieving:
\begin{itemize}
\item 95\% sensitivity at 90\% specificity
\item Reduced false positives through region proposal refinement
\item Effective multi-scale detection
\end{itemize}

Limitations:
\begin{itemize}
\item Inference speed: ~5 FPS (too slow for real-time)
\item Complex training pipeline (RPN + detector)
\item High memory requirements
\end{itemize}

\textbf{Mask R-CNN Variants:}

He et al. \cite{he2017mask} introduced Mask R-CNN, combining object detection with instance segmentation. Medical applications include:
\begin{itemize}
\item Ma et al. \cite{ma2019polyp}: 94\% mAP for polyp detection with masks
\item Zheng et al. \cite{zheng2019polyp}: Multi-task learning for detection and segmentation
\end{itemize}

Trade-offs:
\begin{itemize}
\item Superior accuracy but sacrifices speed
\item Requires bounding box + mask annotations
\item Not suitable for real-time video processing
\end{itemize}

\subsection{One-Stage Detectors}

One-stage detectors prioritize speed while maintaining competitive accuracy, making them ideal for real-time medical applications.

\textbf{SSD (Single Shot MultiBox Detector):}

Liu et al. \cite{liu2016ssd} proposed SSD using multi-scale feature maps for detection. Medical applications:
\begin{itemize}
\item Mahmood et al. \cite{mahmood2018automatic}: SSD for polyp detection achieving 20 FPS with 85\% recall
\item Multi-box predictions at different scales effective for varied polyp sizes
\end{itemize}

\textbf{RetinaNet and Focal Loss:}

Lin et al. \cite{lin2017focal} introduced focal loss addressing class imbalance in dense detection. Benefits for medical imaging:
\begin{itemize}
\item Handles extreme imbalance (few polyps vs. large normal tissue regions)
\item Improved detection of small, difficult polyps
\item State-of-the-art accuracy among one-stage detectors
\end{itemize}

\section{YOLO-Based Medical Image Analysis}
\label{chp2.5}

\subsection{YOLO Architecture Evolution}

The YOLO family has evolved through eight major versions, each improving accuracy and efficiency:

\textbf{YOLOv1 (2016):}
\begin{itemize}
\item First real-time object detector (45 FPS)
\item Single convolutional network predicting bboxes and class probabilities
\item Limitations: Struggled with small objects, spatial constraints
\end{itemize}

\textbf{YOLOv2/YOLO9000 (2017):}
\begin{itemize}
\item Batch normalization and anchor boxes
\item Multi-scale training
\item Better recall and localization
\end{itemize}

\textbf{YOLOv3 (2018):}
\begin{itemize}
\item Multi-scale predictions at three scales
\item Darknet-53 backbone
\item Improved small object detection (critical for small polyps)
\end{itemize}

\textbf{YOLOv4 (2020):}
\begin{itemize}
\item CSPDarknet53 backbone
\item Bag-of-freebies and bag-of-specials
\item State-of-the-art accuracy (43.5\% AP on COCO)
\end{itemize}

\textbf{YOLOv5 (2020):}
\begin{itemize}
\item PyTorch implementation (easier deployment)
\item Auto-learning bounding box anchors
\item Multiple model sizes (nano to xlarge)
\end{itemize}

\textbf{YOLOv6-v7 (2022):}
\begin{itemize}
\item Industrial applications focus
\item Hardware-friendly designs
\item Further speed optimizations
\end{itemize}

\textbf{YOLOv8 (2023):}
\begin{itemize}
\item Anchor-free detection
\item Improved feature pyramid network
\item Better small object detection
\item Unified framework for detection, segmentation, classification
\item State-of-the-art speed-accuracy tradeoff
\end{itemize}

\subsection{YOLO in Medical Imaging}

YOLO architectures have been successfully applied across various medical imaging tasks:

\textbf{Radiology:}
\begin{itemize}
\item Chest X-ray abnormality detection (YOLOv3): 92\% sensitivity \cite{yuan2021chest}
\item CT scan tumor detection (YOLOv5): 89\% mAP \cite{wang2021tumor}
\item MRI lesion detection (YOLOv4): Real-time processing \cite{li2021mri}
\end{itemize}

\textbf{Endoscopy:}
\begin{itemize}
\item Bleeding detection in capsule endoscopy (YOLOv3): 96\% accuracy \cite{segu√≠2017bleeding}
\item Gastric cancer detection (YOLOv5): 93\% precision \cite{kim2021gastric}
\item Esophageal cancer detection (YOLOv4): 88\% mAP \cite{zhao2021esophageal}
\end{itemize}

\textbf{Polyp Detection with YOLO:}

Recent works specifically applying YOLO to polyp detection:

1. \textbf{Ahmad et al. (2021)} \cite{ahmad2021yolo}: YOLOv3 for polyp detection
   \begin{itemize}
   \item Dataset: CVC-ClinicDB (612 frames)
   \item Results: 87\% mAP@50, 25 FPS
   \item Limitations: Small dataset, single polyp type
   \end{itemize}

2. \textbf{Zhang et al. (2022)} \cite{zhang2022polyp}: YOLOv5 variants comparison
   \begin{itemize}
   \item Tested nano, small, medium, large models
   \item Best: YOLOv5-large with 91\% mAP@50
   \item Trade-off analysis: nano (60 FPS) vs. large (20 FPS)
   \end{itemize}

3. \textbf{Yuan et al. (2023)} \cite{yuan2023improved}: Improved YOLOv5 with attention
   \begin{itemize}
   \item Added CBAM attention modules
   \item Improved small polyp detection
   \item 93\% mAP@50 on Kvasir dataset
   \end{itemize}

4. \textbf{Wang et al. (2023)} \cite{wang2023yolov7}: YOLOv7 for real-time colonoscopy
   \begin{itemize}
   \item Multi-scale feature aggregation
   \item 40 FPS with 90\% mAP
   \item Tested on live procedures
   \end{itemize}

\subsection{YOLOv8 in Medical Applications}

YOLOv8, released in January 2023, represents the state-of-the-art in the YOLO family:

\textbf{Architecture Improvements:}
\begin{itemize}
\item \textbf{Anchor-Free}: Eliminates need for predefined anchor boxes, better generalization
\item \textbf{New Backbone}: C2f modules replacing C3, improved feature extraction
\item \textbf{Decoupled Head}: Separate branches for classification and localization
\item \textbf{Task-Aligned Assigner}: Improved positive sample assignment
\item \textbf{Enhanced Augmentation}: Mosaic, mixup, augmentations during training
\end{itemize}

\textbf{Medical Imaging Applications:}
\begin{itemize}
\item Cell detection in microscopy: 95\% mAP \cite{li2023yolov8cell}
\item Dental X-ray analysis: 92\% accuracy \cite{chen2023dental}
\item Ultrasound fetal detection: 89\% mAP \cite{liu2023fetal}
\end{itemize}

\textbf{Advantages for Polyp Detection:}
\begin{enumerate}
\item Anchor-free design adapts to variable polyp morphologies
\item Multi-scale predictions handle small to large polyps
\item Real-time processing (30-60 FPS) suitable for live procedures
\item PyTorch implementation enables easy fine-tuning
\item Comprehensive metrics and visualization tools
\item Production-ready deployment options (ONNX, TensorRT)
\end{enumerate}

\section{Datasets for Polyp Detection}
\label{chp2.6}

\subsection{Public Benchmark Datasets}

\textbf{1. CVC-ClinicDB (2015):}
\begin{itemize}
\item 612 frames from 31 colonoscopy sequences
\item Polyp ground truth annotations
\item Standard benchmark for comparison
\item Limitations: Small size, limited diversity
\end{itemize}

\textbf{2. ASU-Mayo Clinic Dataset (2016):}
\begin{itemize}
\item 20 short colonoscopy videos
\item Frame-level polyp presence labels
\item Polyp size annotations
\item Useful for video-based evaluation
\end{itemize}

\textbf{3. Kvasir-SEG (2020):}
\begin{itemize}
\item 1,000 polyp images with segmentation masks
\item High-quality pixel-level annotations
\item Diverse polyp sizes, shapes, appearances
\item Most widely used recent benchmark
\item Public availability promoting reproducibility
\end{itemize}

\textbf{4. CVC-ColonDB (2012):}
\begin{itemize}
\item 380 frames from 15 short colonoscopy sequences
\item Complementary to CVC-ClinicDB
\item Different acquisition devices
\end{itemize}

\textbf{5. ETIS-Larib (2014):}
\begin{itemize}
\item 196 polyp images
\item Challenging small polyps
\item Often used for cross-dataset validation
\end{itemize}

\subsection{Dataset Challenges}

\begin{itemize}
\item \textbf{Limited Size}: Most medical datasets contain hundreds, not millions of images
\item \textbf{Annotation Cost}: Expert gastroenterologist time expensive
\item \textbf{Class Imbalance}: Far more normal tissue than polyp regions
\item \textbf{Privacy Constraints}: Patient data regulations limit public sharing
\item \textbf{Domain Shift}: Different endoscopy equipment, settings, patient populations
\end{itemize}

\subsection{Data Augmentation Strategies}

To address small dataset limitations:
\begin{itemize}
\item Geometric transformations (rotation, flipping, scaling)
\item Color space augmentations (hue, saturation, brightness)
\item Elastic deformations
\item Mixup and cutmix
\item Synthetic data generation with GANs
\end{itemize}

\section{Performance Metrics for Polyp Detection}
\label{chp2.7}

\subsection{Object Detection Metrics}

\textbf{1. Intersection over Union (IoU):}
\begin{equation}
\text{IoU} = \frac{\text{Area of Overlap}}{\text{Area of Union}} = \frac{|B_{\text{pred}} \cap B_{\text{gt}}|}{|B_{\text{pred}} \cup B_{\text{gt}}|}
\end{equation}

A detection is considered correct if IoU $\geq$ threshold (typically 0.5).

\textbf{2. Precision and Recall:}
\begin{equation}
\text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}, \quad \text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}
\end{equation}

\textbf{3. Average Precision (AP):}
AP summarizes the precision-recall curve:
\begin{equation}
\text{AP} = \int_0^1 P(R) \, dR
\end{equation}

\textbf{4. mean Average Precision (mAP):}
For multi-class detection, mAP averages AP across classes. For single-class (polyp):
\begin{itemize}
\item mAP@50: AP at IoU threshold 0.5
\item mAP@50-95: Average AP across IoU thresholds 0.5 to 0.95 (step 0.05)
\end{itemize}

\subsection{Medical-Specific Metrics}

\textbf{Adenoma Detection Rate (ADR):}
Proportion of procedures detecting at least one adenoma. AI-assisted ADR compared to baseline.

\textbf{Polyp Miss Rate (PMR):}
Percentage of polyps not detected by the system. Critical safety metric.

\textbf{False Positive Rate (FPR):}
Alerts per procedure on normal tissue. High FPR causes alarm fatigue.

\section{Critical Analysis and Research Gaps}
\label{chp2.8}

\subsection{Strengths of Existing Approaches}

\begin{enumerate}
\item Deep learning methods significantly outperform traditional approaches
\item Segmentation models achieve high accuracy (90\%+ Dice coefficient)
\item YOLO-based detectors enable real-time processing
\item Public datasets (Kvasir-SEG) promote reproducibility
\item Transfer learning reduces data requirements
\end{enumerate}

\subsection{Identified Gaps}

\begin{enumerate}
\item \textbf{Limited YOLOv8 Studies}: Despite being state-of-the-art, few works apply YOLOv8 to polyp detection
\item \textbf{Real Video Validation}: Most studies use static image datasets; limited testing on actual colonoscopy videos
\item \textbf{Multi-Morphology Evaluation}: Insufficient validation across diverse polyp types (pedunculated, sessile, flat)
\item \textbf{Production Readiness}: Gap between research prototypes and deployable clinical systems
\item \textbf{Comprehensive Pipeline}: Lack of end-to-end systems from data preparation to deployment
\item \textbf{Reproducibility}: Many studies don't release code, weights, or detailed implementation details
\end{enumerate}

\subsection{Positioning of This Research}

This thesis addresses the identified gaps by:
\begin{itemize}
\item Implementing state-of-the-art YOLOv8 architecture
\item Validating on both benchmark dataset and real medical videos
\item Testing across multiple polyp morphologies (MSD, pedunculated, ileocecal valve)
\item Providing complete, production-ready codebase
\item Delivering comprehensive pipeline from data preprocessing to inference
\item Releasing all code, trained weights, and test results
\item Achieving superior performance (89.4\% mAP@50) with real-time capability
\end{itemize}

\section{Summary}
\label{chp2.9}

This chapter reviewed the evolution of polyp detection methods from traditional hand-crafted features to modern deep learning approaches. Early methods relied on texture and color features with limited success. The deep learning revolution introduced CNNs for classification, U-Net for segmentation, and object detectors (Faster R-CNN, YOLO) for localization. The YOLO family emerged as the optimal choice for real-time medical applications, balancing accuracy and speed.

YOLOv8 represents the current state-of-the-art with anchor-free design, improved architecture, and superior performance. However, limited research exists applying YOLOv8 to polyp detection, particularly with comprehensive real-world validation. This research fills the gap by implementing a complete YOLOv8-based system validated on diverse polyp types and real colonoscopy videos, with production-ready deployment and full reproducibility.
